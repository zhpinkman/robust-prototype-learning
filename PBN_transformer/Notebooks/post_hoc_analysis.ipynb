{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "MOD_FOLDER = \"../\"\n",
    "# setting path to enable import from the parent directory\n",
    "sys.path.append(MOD_FOLDER)\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"ModelTC/bart-base-mnli\")\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"../data/finegrained/train.csv\")\n",
    "val_df = pd.read_csv(\"../data/finegrained/val.csv\")\n",
    "test_df = pd.read_csv(\"../data/finegrained/test.csv\")\n",
    "\n",
    "train_sentences = train_df[\"text\"].tolist()\n",
    "test_sentences = test_df[\"text\"].tolist()\n",
    "train_labels = train_df[\"label\"].tolist()\n",
    "val_labels = val_df[\"label\"].tolist()\n",
    "test_labels = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestk_train_data_per_proto = joblib.load(\n",
    "    \"../artifacts/bestk_train_data_per_proto.joblib\"\n",
    ")\n",
    "best_protos_per_testeg = joblib.load(\"../artifacts/best_protos_per_testeg.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestk_train_data_per_proto[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_protos_per_testeg[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of test example label being present in the topk train sample labels close to the best prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for test_index, test_sample_prototypes in enumerate(best_protos_per_testeg[0]):\n",
    "    test_sample_label = test_labels[test_index]\n",
    "    respective_prototypes_train_labels = []\n",
    "    for prototype in test_sample_prototypes:\n",
    "        prototype_train_labels = []\n",
    "        train_samples_close_to_prototype = bestk_train_data_per_proto[0][prototype]\n",
    "        for train_sample in train_samples_close_to_prototype:\n",
    "            prototype_train_labels.append(train_labels[train_sample])\n",
    "        respective_prototypes_train_labels.append(prototype_train_labels)\n",
    "    results.append((test_sample_label, respective_prototypes_train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_of_model_on_label(results, k=5):\n",
    "    statistics = []\n",
    "    for test_label, prototypes_train_labels in results:\n",
    "        per_test_statistics = []\n",
    "        for prototype_train_labels in prototypes_train_labels:\n",
    "            per_test_statistics.append(test_label in prototype_train_labels)\n",
    "        statistics.append(per_test_statistics)\n",
    "    statistics = np.array(statistics)\n",
    "    return np.round(np.mean(np.sum(statistics[:, :k], axis=1) != 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "accuracies = defaultdict(list)\n",
    "for k in [5, 3, 1]:\n",
    "    overall_accuracy = get_accuracy_of_model_on_label(results, k)\n",
    "    accuracies[k].append(overall_accuracy)\n",
    "    for label in set(train_labels):\n",
    "        if label == \"O\":\n",
    "            continue\n",
    "        label_specific_accuracy = get_accuracy_of_model_on_label(\n",
    "            [result for result in results if result[0] == label], k\n",
    "        )\n",
    "        accuracies[k].append(label_specific_accuracy)\n",
    "report_labels = list(set(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(\n",
    "    {\n",
    "        \"class\": [\"overall\", *report_labels],\n",
    "        \"k = 5\": accuracies[5],\n",
    "        \"k = 3\": accuracies[3],\n",
    "        \"k = 1\": accuracies[1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping prototypes for each training label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_protos_per_traineg = joblib.load(\"../artifacts/best_protos_per_traineg.joblib\")\n",
    "train_prototype_sentences = defaultdict(set)\n",
    "for train_index, train_sample_prototypes in enumerate(best_protos_per_traineg[0]):\n",
    "    for prototype in train_sample_prototypes.tolist()[:3]:\n",
    "        train_prototype_sentences[train_labels[train_index]].add(prototype)\n",
    "for key, values in train_prototype_sentences.items():\n",
    "    print(f\"{key}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_protos_per_testeg = joblib.load(\"../artifacts/best_protos_per_testeg.joblib\")\n",
    "test_prototype_sentences = defaultdict(set)\n",
    "for test_index, test_sample_prototypes in enumerate(best_protos_per_testeg[0]):\n",
    "    for prototype in test_sample_prototypes.tolist()[:3]:\n",
    "        test_prototype_sentences[test_labels[test_index]].add(prototype)\n",
    "for key, values in test_prototype_sentences.items():\n",
    "    print(f\"{key}: {values}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering prototype tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "all_protos = torch.load(\"../artifacts/all_protos.pt\")\n",
    "all_protos = all_protos.cpu()\n",
    "print(all_protos.shape)\n",
    "num_protos = 50\n",
    "all_protos = all_protos.view(num_protos, -1)\n",
    "print(all_protos.shape)\n",
    "print(all_protos.min())\n",
    "print(all_protos.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "all_protos_transformed = pca.fit_transform(all_protos.detach().numpy())\n",
    "print(all_protos_transformed.shape)\n",
    "\n",
    "proto_df = {\n",
    "    \"1st component\": all_protos_transformed[:, 0].tolist(),\n",
    "    \"2nd component\": all_protos_transformed[:, 1].tolist(),\n",
    "    \"Protoypes\": np.arange(1, 51).tolist(),\n",
    "}\n",
    "sns.scatterplot(data=proto_df, x=\"2nd component\", y=\"1st component\", hue=\"Protoypes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, learning_rate=\"auto\", init=\"random\", perplexity=2)\n",
    "all_protos_transformed = tsne.fit_transform(all_protos.detach().numpy())\n",
    "print(all_protos_transformed.shape)\n",
    "\n",
    "proto_df = {\n",
    "    \"X\": all_protos_transformed[:, 0].tolist(),\n",
    "    \"Y\": all_protos_transformed[:, 1].tolist(),\n",
    "    \"Label\": np.arange(1, 51).tolist(),\n",
    "}\n",
    "sns.scatterplot(data=proto_df, x=\"Y\", y=\"X\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "all_protos_transformed = reducer.fit_transform(all_protos.detach().numpy())\n",
    "print(all_protos_transformed.shape)\n",
    "\n",
    "proto_df = {\n",
    "    \"X\": all_protos_transformed[:, 0].tolist(),\n",
    "    \"Y\": all_protos_transformed[:, 1].tolist(),\n",
    "    \"Label\": np.arange(1, 51).tolist(),\n",
    "}\n",
    "sns.scatterplot(data=proto_df, x=\"Y\", y=\"X\", hue=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('prototex': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67a2a78c27fe286f44f928febc9f5314f2b48ea11236d1a7eff6379cd9712b1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
